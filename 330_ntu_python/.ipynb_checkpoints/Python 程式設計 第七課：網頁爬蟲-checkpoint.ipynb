{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdBitnFUNP8j"
   },
   "source": [
    "# 透過 Python 擷取網頁上的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1uW2DSxNP8o"
   },
   "source": [
    "在大數據變成顯學的時代，今天我們要做資料分析，若沒有大量的資料，是無法分析出任何有價值的資訊出來的。\n",
    "\n",
    "但是在一般情況下，我們都沒有大量的資料可以做分析，但幸運的是，由於網路的蓬勃發展，獲取任何一個領域的資料比起過往相對就變得容易許多。但是，由於網頁上的資料非常多，若透過手動的方式截取資料，就不是一個很有效率的方法了。\n",
    "\n",
    "因此這時候，透過程式自動從網路上蒐集資料這個問題也變得更加重要，只需一個簡單的程式，就能透過低成本並且自動化的方式從網頁上獲得大量的資料，因此**學習與實作網頁爬蟲成為一個投資報酬率極高的事務**，而 Python 語言由於生態系龐大，套件衆多，也讓用 Python 實作爬蟲比起其他語言相對簡單許多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4WAmgQyNP8q"
   },
   "source": [
    "## 請先開啓範例網頁：\n",
    "\n",
    "http://pythonscraping.com/pages/warandpeace.html\n",
    "\n",
    "*以上練習用網頁由 Ryan Mitchell 維護，可以的話，大家買一本他的書支持他繼續維護這個網站：[連結](https://www.books.com.tw/products/0010800965)\n",
    "\n",
    "在進入網頁之後，試試看直接點擊網頁，然後右鍵 -> 儲存，接下來瀏覽器會將一個副檔名為 **html** 的檔案存下來。由此我們發現，任何一個我們看得見的網頁，其實都是一個副檔名為 **.html** 的檔案，問題是，這個 **html** 檔案是從何而來？它的原理又是什麽？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irY_iD9GNP8r"
   },
   "source": [
    "## 網頁開發基礎： HTTP 溝通協定\n",
    "\n",
    "HTTP 用白話講，就像是**電腦與電腦之間的共同語言**，電腦需要通過這個共同語言，才能在網絡上面互相溝通。\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1UiDUXriZVo83ePdiSQTLS4QWnCN_YsVu)\n",
    "\n",
    "而一個 HTTP 的請求 (Request) 是根據 **HTTP 動詞** (HTTP Verb) 以及**網址**才能運作，舉例來説，當你在輸入 https://www.google.com/ ，連至 Google 的首頁時，整個背後的運作流程是：\n",
    "\n",
    "1. 用戶端 (你的瀏覽器) 針對 Google 的雲端伺服器發送了一個 GET Request\n",
    "2. 而 Google 的雲端伺服器在收到請求後，將需要呈現該網頁的資料都計算完成\n",
    "3. 接著 Google 的雲端伺服器會回傳一個回應 (Response)，這個 Response 内通常就包含了一個 html 檔案\n",
    "4. 用戶端 (你的瀏覽器) 在下載了請求回傳的 html 檔案之後，將 html 程式碼渲染成網頁，呈現給使用者\n",
    "\n",
    "## HTTP Request 的種類\n",
    "\n",
    "一般來説，Request 有 GET 與 POST：\n",
    "\n",
    "- GET 代表我需要查詢 / 顯示資料，像是 GET https://www.facebook.com/ 代表查詢 facebook 首頁\n",
    "- POST 代表我需要新增資料，通常用於網頁上的表單，像是 POST https://www.foodpanda.com/orders 代表新增訂單\n",
    "\n",
    "## HTTP response 的種類\n",
    "\n",
    "- 一般伺服器通常是回傳 html 網頁檔案\n",
    "- 但若是一些功能像是下載 / 輸出報表，Response 則是一個 xlsx / csv 檔案\n",
    "\n",
    "\n",
    "## 從 Excel 的角度來理解...\n",
    "\n",
    "像是 FB, Google, Yahoo 等網站，**其實都像是一個個運行在雲端上的 Excel 函數**。\n",
    "\n",
    "而要使用該函數時，就必須透過一個 HTTP 的請求 (Request) 來呼叫該函數。讓瀏覽器發送 HTTP Request 的方法就是輸入網址，就像是在 Excel 上輸入公式一樣。\n",
    "\n",
    "而該公式若執行成功，不同於 Excel 是將結果顯示在工作表上，HTTP Request 的結果就是一個 Response，該 Response 通常是顯示在瀏覽器上的網頁，也有可能是 xlsx / csv 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXd_i_QONP8t"
   },
   "source": [
    "\n",
    "## 用 Python 實作爬蟲\n",
    "\n",
    "Python 用來實作爬蟲的兩個主流套件：\n",
    "\n",
    "- BeautifulSoup [官方文件](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)\n",
    "\n",
    "- PyQuery [官方文件](https://pythonhosted.org/pyquery/)\n",
    "\n",
    "簡單來説：\n",
    "\n",
    "**BeautifulSoup** 是比較貼近**程式設計師**的角度去思考\n",
    "\n",
    "**PyQuery** 貼近**網頁開發者**的角度去思考\n",
    "\n",
    "在這堂課考量到並不是每一個人都具備網頁開發的背景，因此我們會使用 BeautifulSoup 套件來實作爬蟲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ac0N9fsvNP8u"
   },
   "source": [
    "## 網頁開發 101\n",
    "\n",
    "任何網頁都是由 **html 標籤(tag)** 所組成，基本結構如下\n",
    "```html\n",
    "<標籤名稱 class=\"類別名稱\">內容</標籤名稱>\n",
    "<標籤名稱 id=\"id名稱\">內容</標籤名稱>\n",
    "```\n",
    "今天我們要擷取的任何內容，一定是被包裹在在某一個標籤裡面\n",
    "而今天若網頁開發者需要改變任何一個標籤的**樣式**，就需要用到 **css** 語法\n",
    "以上面的網頁為例，人名都是以綠色顯示，所以就先宣告一個名為 **green** 的 css 類別:\n",
    "\n",
    "```html\n",
    "<style>\n",
    ".green{\n",
    "\tcolor:#55ff55;\n",
    "}\n",
    "</style>\n",
    "```\n",
    "\n",
    "若今天希望讓一個標籤的内容文字變成綠色，可以使用定義好的 .green 這個 css 類別：\n",
    "\n",
    "```html\n",
    "<span class=\"green\">Prince Vasili Kuragin</span>\n",
    "```\n",
    "\n",
    "*想了解更多 html 可以看一下 Mozilla 官網的教學：[HTML 基礎](https://developer.mozilla.org/zh-TW/docs/Learn/Getting_started_with_the_web/HTML_basics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> War and Peace </h1> #h表示header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ov5EcSJNP8w"
   },
   "source": [
    "## 使用 標籤 「類別名稱」取得資料\n",
    "\n",
    "要擷取資料前，首先需要透過方法**選擇**到該標籤\n",
    "##  BeautifulSoup 套件\n",
    "\n",
    "典故來自 Alice in WonderLand 裏面一首同名的詩，由假海龜 (Mock Turtle) 所唱，影射英國料理假海龜湯...\n",
    "\n",
    "有興趣自己可以去 Google, 不多説了...\n",
    "\n",
    "想查看 BeautifulSoup 套件的功能請看一下官方的中文文件：\n",
    "\n",
    "[BeautifulSoup 官方文件](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByfQTMtkNP8x"
   },
   "source": [
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# 針對網頁發送 GET Reqeust\n",
    "res = requests.get(\"http://pythonscraping.com/pages/warandpeace.html\")\n",
    "# 將回傳的 Response 内的文字用 BeautifulSoup 解析\n",
    "html = BeautifulSoup(res.text, \"html.parser\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ho8oDCIuNP8y",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Glgijf4iNP83"
   },
   "source": [
    "## 另外再介紹一下 find() 方法...\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get(\"http://pythonscraping.com/pages/warandpeace.html\")\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "# 我們把該網頁使用 'green' css 類別的 span 標籤過濾出來...\n",
    "name = html.find(\"span\", {\"class\": \"green\"})\n",
    "print(name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXHpzZlHNP85",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyArZIqTNP8-"
   },
   "source": [
    "# 網頁爬蟲實戰：(臺股爬蟲)\n",
    "\n",
    "我們想要截取資料的網頁：[Yahoo Stock 台積電](https://tw.stock.yahoo.com/q/q?s=2330)\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1samMUBW19ooC7UsntphFGG6QKjL5337R)\n",
    "\n",
    "網址是：\n",
    "\n",
    "https://tw.stock.yahoo.com/q/q?s=2330\n",
    "\n",
    "```python\n",
    "# 來試試看爬 yahoo stock 的網頁...\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "# 用 html 格式解碼 爬下來的檔案\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "print(html)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxK2DxaPNP8_",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNIIkoriNP9C"
   },
   "source": [
    "# 問題是找到有用的資料如同大海撈針...\n",
    "\n",
    "---\n",
    "## 分析一下我們要爬的網頁\n",
    "\n",
    "收盤價是被封裝在一個 **table** 標籤内部的一個 **td** 標籤\n",
    "\n",
    "\n",
    "---\n",
    "## table 標籤\n",
    "\n",
    "一般網頁若要呈現重要的資訊，都會將資訊以網頁表格的形式呈現\n",
    "\n",
    "今天若要利用 **html** 實作網頁上的表格，需要名爲 **table** 的標籤\n",
    "\n",
    "換句話説，今天網頁上我們有興趣的資料，十之八九都是被封裝在 **table** 底下\n",
    "\n",
    "把 **table** 的結構搞懂，就成了一件重要的事情。\n",
    "\n",
    "---\n",
    "# html table 標籤的結構\n",
    "\n",
    "網頁上的資料大多都是匯整在表格、而 html 的表格則是由 table 標籤構成的：\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1dmYx5qOD21tPWHATzIm6IxDnfO96sUac)\n",
    "\n",
    "該 **table** 標籤内有兩個 **tr** 標籤\n",
    "\n",
    "第二個 tr 標籤内的第八個 td 標簽是我們要的收盤價\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=109M71HQtR-kfZMklVit7AZRpIH4zhfe_)\n",
    "\n",
    "---\n",
    "# html 標簽的關聯\n",
    "\n",
    "簡單來説，就是一個樹狀圖的概念：\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1n2yZlQtj7EK2_NNIBXvEVGeEKBogfgYZ)\n",
    "\n",
    "---\n",
    "# 延申閲讀\n",
    "\n",
    "HTML Table 教學\n",
    "\n",
    "w3 school： [連結](https://www.w3schools.com/html/html_tables.asp)\n",
    "\n",
    "Mozilla：[連結](https://developer.mozilla.org/zh-TW/docs/Web/HTML/Element/table)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFh0F2spNP9D"
   },
   "source": [
    "## 開始實作台股爬蟲\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "# 搜尋整個網頁裡的 table 標籤，將所有的表格讀取出來\n",
    "html.findAll(\"table\")\n",
    "# 我們就發現網頁内有多個 table...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBGjdatZNP9E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59hS4xnVaDCE"
   },
   "source": [
    "## 檢查所有搜尋到的 table\n",
    "\n",
    "仔細觀察一下，我們發現目標 table 的 **border** 屬性是被設定成 **2**\n",
    "\n",
    "因此我們可以將程式碼修改爲...\n",
    "\n",
    "```python\n",
    "table = html.findAll(\"table\", { \"border\": 2 })[0]\n",
    "table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUQ9ViEONP9H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lsT3W1eaDCJ"
   },
   "source": [
    "## 找尋 table 裡第二個 tr 標籤內所有的 td 標籤\n",
    "\n",
    "```python\n",
    "table_row = table.findAll(\"tr\")[1]\n",
    "tds = table_row.findAll(\"td\")\n",
    "tds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3vcd7soaDCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6onuMQwaDCQ"
   },
   "source": [
    "## 讀取出昨日收盤價\n",
    "\n",
    "```python\n",
    "last_close = tds[7].text\n",
    "print(f\"台積電今日收盤價：${last_close}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KSpFBzTaDCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSeetJ4YaDCV"
   },
   "source": [
    "## 完成版網頁爬蟲\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "table = html.findAll(\"table\", { \"border\": 2 })[0]\n",
    "# 找尋 table 裡第二個 tr 標籤內所有的 td 標籤\n",
    "table_row = table.findAll(\"tr\")[1]\n",
    "tds = table_row.findAll(\"td\")\n",
    "# 選取該 row 第八個 td 標籤，擷取標籤內文字\n",
    "last_close = tds[7].text\n",
    "print(f\"台積電昨日收盤價：${last_close}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrGlPvDlNP9V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHafy1EYNP9Y"
   },
   "source": [
    "## 解法二\n",
    "\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "doc = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(doc.text, 'html.parser')\n",
    "# 搜尋整個網頁裡，內容為 '個股資料' 的 html 標籤, 關聯到 table 最外層\n",
    "table = html.findAll(text='個股資料')[0].parent.parent.parent\n",
    "# 找尋 table 裡第二個 tr 標籤內所有的 td 標籤\n",
    "data_row = table.findAll('tr')[1].findAll('td')\n",
    "# 選取該 row 第八個 td 標籤，擷取標籤內文字\n",
    "last_price = data_row[7].text\n",
    "print(f\"台積電昨日收盤價：${last_close}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Y9gY6DEaDCf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z74jEMrYNP9a"
   },
   "source": [
    "## 解法三...\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1IJp5dze4stcwni0FNs2ThIjzYM_vYp4o)\n",
    "\n",
    "注意 **tt** 是一個獨特的 css class，而 **tt** 只有被套用在最後一個 **td** 標籤上\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "doc = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(doc.text, 'html.parser')\n",
    "# 尋找 class 屬性為 tt 的 td 標籤\n",
    "last_td = html.find(\"td\", {\"class\": \"tt\"})\n",
    "# find_previous_sibling('td') 代表尋找前一個 (左邊) td 標籤\n",
    "last_close = last_td.find_previous_sibling('td').find_previous_sibling('td').find_previous_sibling('td').find_previous_sibling('td').text\n",
    "print(f\"台積電昨日收盤價：${last_close}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T83NABz0NP9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bPEdH8H-NP9g"
   },
   "source": [
    "## 隨堂練習\n",
    "\n",
    "請試試看從 Yahoo 股市網頁將 2330 的**開盤價、最高價、最低價**、以及**成交價**讀取出來：\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "table = html.findAll(\"table\", { \"border\": 2 })[0]\n",
    "# 找尋 table 裡第二個 tr 標籤內所有的 td 標籤\n",
    "table_row = table.findAll(\"tr\")[1]\n",
    "tds = table_row.findAll(\"td\")\n",
    "# 選取該 row 第八個 td 標籤，擷取標籤內文字\n",
    "last_close = tds[7].text\n",
    "open_price = ________________\n",
    "high_price = ________________\n",
    "low_price = ________________\n",
    "close_price = ________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlFWh49oNP9g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvX3ORI1NP9i"
   },
   "source": [
    "## 將結果寫入 Excel\n",
    "\n",
    "用 xlwings 開啓 **stock_price_data.xlsx**：\n",
    "\n",
    "```python\n",
    "import xlwings as xw\n",
    "import time\n",
    "\n",
    "wb = xw.Book(r\"stock_price_data.xlsx\")\n",
    "sheet = wb.sheets[\"2330\"]\n",
    "```\n",
    "\n",
    "偵測最後一個 row:\n",
    "\n",
    "```python\n",
    "last_row = sheet.range(\"A1\").end(\"down\").row\n",
    "last_row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcThVQ8XNP9j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcvNEFsnNP9l"
   },
   "source": [
    "## 產生格式化的時間字串\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "time.strftime(\"%Y/%m/%d\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cb1Lg6kVNP9n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9FWOzKDaDC8"
   },
   "source": [
    "## 將時間與收盤價寫入 Excel \n",
    "\n",
    "```python\n",
    "sheet.range(f\"A{last_row+1}\").value = time.strftime(\"%Y/%m/%d\")\n",
    "sheet.range(f\"B{last_row+1}\").value = closing_price\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9b8G_zA0aDC-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGZboTzgNP9r"
   },
   "source": [
    "# 完成版程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQvsI2xYNP9v"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import xlwings as xw\n",
    "# 截取台積電的資料 \n",
    "res = requests.get('https://tw.stock.yahoo.com/q/q?s=2330')\n",
    "html = BeautifulSoup(res.text, 'html.parser')\n",
    "table = html.findAll(\"table\", { \"border\": 2 })[0]\n",
    "table_row = table.findAll(\"tr\")[1]\n",
    "tds = table_row.findAll(\"td\")\n",
    "closing_close = tds[2].text\n",
    "# 將台積電資料寫入 Excel\n",
    "wb = xw.Book(r\"stock_price_data.xlsx\")\n",
    "date = time.strftime(\"%Y/%m/%d\")\n",
    "sheet = wb.sheets[\"TW2330\"]\n",
    "last_row = sheet.range(\"B1\").end(\"down\").row\n",
    "sheet.range(f\"B{last_row+1}\").value = closing_price\n",
    "sheet.range(f\"A{last_row+1}\").value = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tUUe7yTNP9y"
   },
   "source": [
    "# 小結：\n",
    "\n",
    "1. 學習與實作網頁爬蟲是一個**投資報酬率極高的事務**\n",
    "2. Python 語言由於使用者衆多，**與爬蟲相關的套件、解決方案、與教學也多，讓實作變得相對簡單**\n",
    "3. 實作上，最困難的部分在於**解析網頁的 html 結構**\n",
    "4. 網頁的資料很大的機率都是被封裝在 **table** 這個 html 標簽下\n",
    "5. 但若今天**網頁改版，原先寫好的爬蟲就有可能截取不到資料**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwXBkvxCNP9z"
   },
   "source": [
    "# 功課：匯率爬蟲\n",
    "\n",
    "請寫一個網頁爬蟲，截取臺灣銀行牌告匯率網頁：\n",
    "\n",
    "http://rate.bot.com.tw/xrt?Lang=zh-TW\n",
    "\n",
    "\n",
    "並且將匯率資料用以下格式呈現在 Excel 内：\n",
    "![](https://drive.google.com/uc?export=download&id=1YCl-QcAJCW951AhosB3HhuV7Fwy3hjMZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUCCt1ObNP90"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python 程式設計 第七課：網頁爬蟲.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
